{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bbc3ed",
   "metadata": {},
   "source": [
    "# Tutorial #1\n",
    "In this tutorial, a model is trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604595a-853d-4192-ac7c-480faef832dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pre-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f96a48-570f-49be-8062-21766cc38d77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### NeuralLib package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989c88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to be removed once the package is stable\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of your project directory\n",
    "project_path = os.path.abspath(\"..\")\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3112482-af3d-4f55-af8c-ef686a497287",
   "metadata": {},
   "source": [
    "##### Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f5c21",
   "metadata": {},
   "source": [
    "Also, it is necessary to make sure that a conda env or a virtual env with the necessary packages (check requirements.txt) is activated.\n",
    "\n",
    "And, for that, you need to install the IPython kernel in your virtual environment to use it with Jupyter: check steps 6 through 8 in https://medium.com/@WamiqRaza/how-to-create-virtual-environment-jupyter-kernel-python-6836b50f4bf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8300fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# check if it is running the python from the virtual environment you want\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96052d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ea4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralLib.config import DATASETS_GIB01  # directories saved in config.py\n",
    "from NeuralLib.architectures import GRUseq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a69cb-9bcd-4880-98c5-240ebe6c1a9b",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ade310",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = os.path.join(DATASETS_GIB01, 'x')\n",
    "Y = os.path.join(DATASETS_GIB01, 'y_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec8220",
   "metadata": {},
   "source": [
    "### Step 1: Define architecture's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f63b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_params = {\n",
    "    'model_name': 'ECGPeakDetector',\n",
    "    'n_features': 1,\n",
    "    'hid_dim': 16,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 0.01,\n",
    "    'bidirectional': True,\n",
    "    'task': 'classification',\n",
    "    'num_classes': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a21aea",
   "metadata": {},
   "source": [
    "### Step 2: Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014fdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal values for testing purposes\n",
    "train_params = {\n",
    "    'path_x': X,\n",
    "    'path_y': Y,\n",
    "    'epochs': 3,\n",
    "    'batch_size': 1,\n",
    "    'patience': 2,\n",
    "    'dataset_name': 'private_gib01',\n",
    "    'trained_for': 'peak detection',\n",
    "    'all_samples': False,\n",
    "    'samples': 3,\n",
    "    'gpu_id': None,\n",
    "    'enable_tensorboard': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece33149-d582-47ab-81ed-9de1e1f6163a",
   "metadata": {},
   "source": [
    "### Step 3: Initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9eb0c-8d20-4999-8946-93fa7b0396e8",
   "metadata": {},
   "source": [
    "Define the model's architecture (check biosignals_architectures.py) and set the hyperparameters.\n",
    "\n",
    "As `task` is set to `classification`, and has 1 class (binary classification) the criterion (loss function) is automatically set to `BCEWithLogitsLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27f97db-e8e5-4ea1-b02d-7f1bd4726fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUseq2seq(**arch_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb6ec51-e7d3-4c54-8096-fcc04d33a926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRUEncoderDecoder',\n",
       " 'GRUseq2one',\n",
       " 'GRUseq2seq',\n",
       " 'TransformerEncoderDecoder',\n",
       " 'Transformerseq2one',\n",
       " 'Transformerseq2seq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check which classes of architectures are available\n",
    "from NeuralLib.architectures import list_architectures\n",
    "list_architectures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fa0e8-60d4-4869-aa12-c9ff4ec98c2b",
   "metadata": {},
   "source": [
    "### Step 4: Train the model (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67909ca5-cf7d-4be4-ba6c-102b025d62dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 6.6 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 33     | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "6.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db0da113ff342c39bf9d4e46d6c983d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22627e19161a4b30b872b6ea370c3d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dee5867690456384b79446449f104f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f443ab472cd84ac2ae65f5d7ea25ea2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8b90d438c048638dc87b0e223f6c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 54.91 seconds\n",
      "{'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.034851472824811935, 'training_time': 54.91203784942627, 'retraining': False}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\GRUseq2seq_[16, 16]hid_2l_lr0.01_drop[0.3, 0.3].ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "model.train_from_scratch(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c147ac56-4e18-44c5-8cdf-7ef64c291f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\n"
     ]
    }
   ],
   "source": [
    "# checkpoints directory\n",
    "checkpoints_dir = model.checkpoints_directory\n",
    "print(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d42212-34b4-44c0-a9f5-970844dda628",
   "metadata": {},
   "source": [
    "Breakdown of train_from_scratch:\n",
    "1. **Model Initialization & Checkpoints:**\n",
    "\n",
    "A directory for storing model checkpoints is created in \n",
    "`<DEV_BASE_DIR>/results/<model_name>/checkpoints/<architecture_name_hparams_datetime>`\n",
    "\n",
    "2. **Dataset & DataLoader Preparation:**\n",
    "\n",
    "Training and validation datasets are instantiated from `DatasetSequence`, loading data from `path_x` (iputs) and `path_y` (outputs). PyTorch `DataLoader` objects are created. It is prepared to handle dynamic sequence lengths. `path_x` and `path_y` must contain `val`, `train`, and `test` folders. \n",
    "\n",
    "3. **Defining Callbacks for Training:**\n",
    "    - **Checkpoint Callback:** Saves the best model based on validation loss (`val_loss`).\n",
    "    - **Early Stopping Callback:** Stops training early if validation loss doesn't improve for `patience` epochs.\n",
    "    - **Loss Plot Callback:** Saves a loss curve to visualize training progress.\n",
    "\n",
    "4. **Trainer Initialization & Logging:**\n",
    "    - If TensorBoard is enabled, a `TensorBoardLogger` is set up for tracking metrics and hyperparameters (hparams.yaml). These are written inside the checkpoint directory\n",
    "    - The PyTorch Lightning `Trainer` is instantiated, specifying: maximum epochs (`epochs`), device, callbacks (Checkpointing, Early Stopping, Loss Plot), logging\n",
    "    \n",
    "5. **Training Execution:**\n",
    "\n",
    "The model is trained using `trainer.fit(model, train_dataloader, val_dataloader)`.\n",
    "\n",
    "6. **Post-Training Processing & Model Saving:**\n",
    "    - The **best (lowest) validation loss** is extracted from the checkpoint callback.\n",
    "    - Training metadata (trainer state, optimizer, dataset, GPU info, loss, etc.) is saved (using `model.save_training_information()`) and written to `training_info.json` inside the checkpoint directory.\n",
    "    - The **final model weights** (corresponding to the lowest validation loss) are saved in `model_weights.pth` inside the checkpoint directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b3f90-2bbc-47be-9d05-962ccf0fcc97",
   "metadata": {},
   "source": [
    "### Step 5 (optional): Retrain the model\n",
    "##### In this case, we are just continuing the training process for 4 more epochs (did not change anything, nor the data, nor the parameters, nor the task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c192a6-c6d7-4aef-80fd-a171d137e9f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-02-03_15-55-46 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 6.6 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 33     | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "6.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Found existing .pth file: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\model_weights.pth\n",
      "Weights loaded successfully from C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\model_weights.pth\n",
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-02-03_15-55-46\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18a13c3b0634fcfa3e644f7631d70a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e841553f7b4a2da40f8f12f10cf4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be2004c93fe48809223d67320bf8606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3838cc43f804dfaa364f8fa7cf5c88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd4fe73a9a74d6e92f7397f3d3c65ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 53.98 seconds\n",
      "{'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.02943500317633152, 'training_time': 53.97588133811951, 'retraining': True, 'training_history': {'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.034851472824811935, 'training_time': 54.91203784942627, 'retraining': False}}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-02-03_15-55-46\\GRUseq2seq_[16, 16]hid_2l_lr0.01_drop[0.3, 0.3]_retraining.ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-02-03_15-55-46\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "train_params_retrain = train_params.copy()\n",
    "train_params_retrain['epochs'] = 4\n",
    "model.retrain(\n",
    "    checkpoints_directory=checkpoints_dir, # checkpoints directory where the models weights and parameters were stored in the previous step\n",
    "    path_x=train_params_retrain['path_x'],\n",
    "    path_y=train_params_retrain['path_y'],\n",
    "    patience=train_params_retrain['patience'],\n",
    "    batch_size=train_params_retrain['batch_size'],\n",
    "    epochs=train_params_retrain['epochs'],\n",
    "    gpu_id=train_params_retrain['gpu_id'],\n",
    "    all_samples=train_params_retrain['all_samples'],\n",
    "    samples=train_params_retrain['samples'],\n",
    "    dataset_name=train_params_retrain['dataset_name'],\n",
    "    trained_for=train_params_retrain['trained_for'],\n",
    "    enable_tensorboard=train_params_retrain['enable_tensorboard'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3cda0-2a58-4608-80ab-b68995b318b7",
   "metadata": {},
   "source": [
    "### Step 6: Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0593ee03-7955-42be-bfb8-57e6ec4840bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Using device: cpu\n",
      "Weights successfully loaded from C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-02-03_15-54-50\\model_weights.pth.\n",
      "Sample 0: Test Loss: 0.0362\n",
      "Sample 1: Test Loss: 0.0362\n",
      "Sample 2: Test Loss: 0.0373\n",
      "Sample 3: Test Loss: 0.0373\n",
      "Sample 4: Test Loss: 0.0373\n",
      "Average Test Loss: 0.0368\n",
      "Average Test Loss: 0.0368\n"
     ]
    }
   ],
   "source": [
    "predictions, avg_loss = model.test_on_test_set(\n",
    "    path_x=train_params['path_x'],\n",
    "    path_y=train_params['path_y'],\n",
    "    checkpoints_dir=checkpoints_dir,\n",
    "    gpu_id=train_params['gpu_id'],\n",
    "    all_samples=False, # if True, test on all available samples\n",
    "    samples=5,\n",
    "    save_predictions=True\n",
    ")\n",
    "\n",
    "print(f\"Average Test Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432194ef-477d-4a6f-a307-094a4011d956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
