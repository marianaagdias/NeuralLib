{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bbc3ed",
   "metadata": {},
   "source": [
    "# Tutorial #1\n",
    "In this tutorial, a model is trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604595a-853d-4192-ac7c-480faef832dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pre-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f96a48-570f-49be-8062-21766cc38d77",
   "metadata": {},
   "source": [
    "##### NeuralLib package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989c88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to be removed once the package is stable\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of your project directory\n",
    "project_path = os.path.abspath(\"..\")\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3112482-af3d-4f55-af8c-ef686a497287",
   "metadata": {},
   "source": [
    "##### Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f5c21",
   "metadata": {},
   "source": [
    "Also, it is necessary to make sure that a conda env or a virtual env with the necessary packages (check requirements.txt) is activated.\n",
    "\n",
    "And, for that, you need to install the IPython kernel in your virtual environment to use it with Jupyter: check steps 6 through 8 in https://medium.com/@WamiqRaza/how-to-create-virtual-environment-jupyter-kernel-python-6836b50f4bf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8300fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# check if it is running the python from the virtual environment you want\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96052d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ea4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralLib.config import DATASETS_GIB01  # directories saved in config.py\n",
    "from NeuralLib.architectures import GRUseq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a69cb-9bcd-4880-98c5-240ebe6c1a9b",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ade310",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = os.path.join(DATASETS_GIB01, 'x')\n",
    "Y = os.path.join(DATASETS_GIB01, 'y_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec8220",
   "metadata": {},
   "source": [
    "### Step 1: Define architecture's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f63b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_params = {\n",
    "    'model_name': 'ECGPeakDetector',\n",
    "    'n_features': 1,\n",
    "    'hid_dim': 16,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 0.01,\n",
    "    'bidirectional': True,\n",
    "    'task': 'classification',\n",
    "    'num_classes': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a21aea",
   "metadata": {},
   "source": [
    "### Step 2: Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014fdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal values for testing purposes\n",
    "train_params = {\n",
    "    'path_x': X,\n",
    "    'path_y': Y,\n",
    "    'epochs': 3,\n",
    "    'batch_size': 1,\n",
    "    'patience': 2,\n",
    "    'dataset_name': 'private_gib01',\n",
    "    'trained_for': 'peak detection',\n",
    "    'all_samples': False,\n",
    "    'samples': 3,\n",
    "    'gpu_id': None,\n",
    "    'enable_tensorboard': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece33149-d582-47ab-81ed-9de1e1f6163a",
   "metadata": {},
   "source": [
    "### Step 3: Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27f97db-e8e5-4ea1-b02d-7f1bd4726fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUseq2seq(**arch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fa0e8-60d4-4869-aa12-c9ff4ec98c2b",
   "metadata": {},
   "source": [
    "### Step 4: Train the model (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67909ca5-cf7d-4be4-ba6c-102b025d62dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 6.6 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 33     | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "6.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec237e6a0e24f938deb3fc984bc5f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9ac2a1814646e4b02a2d4d0adf53e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320dcdb7057a4958a931665898b4a824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f2dd1f41014097a18607d17f3192a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ddc4218e8f4ae38bbde3da31699d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 54.02 seconds\n",
      "{'architecture': 'GRUseq2seq', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.0354745090007782, 'training_time': 54.01985764503479, 'retraining': False}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\GRUseq2seq_[16, 16]hid_2l_lr0.01_drop[0.3, 0.3].ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "model.train_from_scratch(\n",
    "    path_x=train_params['path_x'],\n",
    "    path_y=train_params['path_y'],\n",
    "    patience=train_params['patience'],\n",
    "    batch_size=train_params['batch_size'],\n",
    "    epochs=train_params['epochs'],\n",
    "    gpu_id=train_params['gpu_id'],\n",
    "    all_samples=train_params['all_samples'],\n",
    "    samples=train_params['samples'],\n",
    "    dataset_name=train_params['dataset_name'],\n",
    "    trained_for=train_params['trained_for'],\n",
    "    enable_tensorboard=train_params['enable_tensorboard']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c147ac56-4e18-44c5-8cdf-7ef64c291f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\n"
     ]
    }
   ],
   "source": [
    "# checkpoints directory\n",
    "checkpoints_dir = model.checkpoints_directory\n",
    "print(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b3f90-2bbc-47be-9d05-962ccf0fcc97",
   "metadata": {},
   "source": [
    "### Step 5 (optional): Retrain the model\n",
    "##### In this case, we are just continuing the training process for 4 more epochs (did not change anything, nor the data, nor the parameters, nor the task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c192a6-c6d7-4aef-80fd-a171d137e9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-01-31_10-38-06 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 6.6 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 33     | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "6.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Found existing .pth file: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\model_weights.pth\n",
      "Weights loaded successfully from C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\model_weights.pth\n",
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-01-31_10-38-06\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ce4611bf56450ba6e044977446bd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce087c83c9a14936ac001157ae123cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3cee0a869f49f3a1fd92b221c4d8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5309a1ea3de43edb22a968cc718adc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c813502fc6e44cfbf379151522046f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 53.36 seconds\n",
      "{'architecture': 'GRUseq2seq', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.029370620846748352, 'training_time': 53.358970403671265, 'retraining': True, 'training_history': {'architecture': 'GRUseq2seq', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 3, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.01\\n    lr: 0.01\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.01, 'validation_loss': 0.0354745090007782, 'training_time': 54.01985764503479, 'retraining': False}}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-01-31_10-38-06\\GRUseq2seq_[16, 16]hid_2l_lr0.01_drop[0.3, 0.3]_retraining.ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_retraining_dt2025-01-31_10-38-06\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "train_params_retrain = train_params.copy()\n",
    "train_params_retrain['epochs'] = 4\n",
    "model.retrain(\n",
    "    checkpoints_directory=checkpoints_dir, # checkpoints directory where the models weights and parameters were stored in the previous step\n",
    "    path_x=train_params_retrain['path_x'],\n",
    "    path_y=train_params_retrain['path_y'],\n",
    "    patience=train_params_retrain['patience'],\n",
    "    batch_size=train_params_retrain['batch_size'],\n",
    "    epochs=train_params_retrain['epochs'],\n",
    "    gpu_id=train_params_retrain['gpu_id'],\n",
    "    all_samples=train_params_retrain['all_samples'],\n",
    "    samples=train_params_retrain['samples'],\n",
    "    dataset_name=train_params_retrain['dataset_name'],\n",
    "    trained_for=train_params_retrain['trained_for'],\n",
    "    enable_tensorboard=train_params_retrain['enable_tensorboard'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3cda0-2a58-4608-80ab-b68995b318b7",
   "metadata": {},
   "source": [
    "### Step 6: Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0593ee03-7955-42be-bfb8-57e6ec4840bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU.\n",
      "Using device: cpu\n",
      "Weights successfully loaded from C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[16, 16]hid_2l_bidirTrue_lr0.01_drop[0.3, 0.3]_dt2025-01-31_10-36-34\\model_weights.pth.\n",
      "Sample 0: Test Loss: 0.0369\n",
      "Sample 1: Test Loss: 0.0369\n",
      "Sample 2: Test Loss: 0.0380\n",
      "Sample 3: Test Loss: 0.0380\n",
      "Sample 4: Test Loss: 0.0380\n",
      "Average Test Loss: 0.0376\n",
      "Average Test Loss: 0.0376\n"
     ]
    }
   ],
   "source": [
    "predictions, avg_loss = model.test_on_test_set(\n",
    "    path_x=train_params['path_x'],\n",
    "    path_y=train_params['path_y'],\n",
    "    checkpoints_dir=checkpoints_dir,\n",
    "    gpu_id=train_params['gpu_id'],\n",
    "    all_samples=False, # if True, test on all available samples\n",
    "    samples=5,\n",
    "    save_predictions=True\n",
    ")\n",
    "\n",
    "print(f\"Average Test Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432194ef-477d-4a6f-a307-094a4011d956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
