{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7737c2af-619c-4d5c-af79-4abc40670518",
   "metadata": {},
   "source": [
    "# Tutorial #2\n",
    "In this tutorial, you will\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ba0d6-fa32-4c50-9497-f405bec1c804",
   "metadata": {},
   "source": [
    "### Pre-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec655dc-fdad-4d4f-aa9d-7b540b9dc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to be removed once the package is stable\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of your project directory\n",
    "project_path = os.path.abspath(\"..\")\n",
    "\n",
    "# Add the project directory to sys.path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e9230-3a7e-4962-a268-d56632d3ba6e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eaa945a-50ba-40f7-b36c-42226cc56a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralLib.config import DATASETS_GIB01  # directory saved in config.py\n",
    "import NeuralLib.architectures as arc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055e53e-b018-4e25-8b36-2c201223179f",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967c5cdb-c6cb-444a-9fce-d10565a2b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = os.path.join(DATASETS_GIB01, 'x')\n",
    "Y = os.path.join(DATASETS_GIB01, 'y_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad8842-2471-4a1a-bbe1-f1b2aeafbac3",
   "metadata": {},
   "source": [
    "### Step 1: Define architecture and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838a86e3-aafe-496c-9174-8363a5cfb956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GRUEncoderDecoder', 'GRUseq2one', 'GRUseq2seq', 'TransformerEncoderDecoder', 'TransformerSeq2One', 'TransformerSeq2Seq']\n"
     ]
    }
   ],
   "source": [
    "architecture_name = 'GRUseq2seq'\n",
    "print(arc.get_valid_architectures())\n",
    "archi_params_options = {\n",
    "    \"model_name\": \"ECGPeakDetector\",\n",
    "    \"n_features\": [1],\n",
    "    \"hid_dim\": [[32, 64, 64], [64, 64, 64], [64, 128, 64], [64, 128]],\n",
    "    \"n_layers\": [3, 2],\n",
    "    \"dropout\": [0.3, 0],\n",
    "    \"learning_rate\": [0.001],\n",
    "    \"bidirectional\": [True],\n",
    "    \"task\": [\"classification\"],\n",
    "    \"num_classes\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce1320c-0600-4a8b-863a-8abb75742cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'path_x': X,\n",
    "    'path_y': Y,\n",
    "    'epochs': 2,\n",
    "    'batch_size': 1,\n",
    "    'patience': 2,\n",
    "    'dataset_name': 'private_gib01',\n",
    "    'trained_for': 'peak detection',\n",
    "    'all_samples': False,\n",
    "    'samples': 3,\n",
    "    'gpu_id': None,\n",
    "    'enable_tensorboard': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dae8b-6ea5-490c-8d90-6c47e91fbb59",
   "metadata": {},
   "source": [
    "### Step 2: Perform grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079a2ef-c6f2-4bbb-869a-78c706d8d4bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search with 16 combinations.\n",
      "\n",
      "Training model 1/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [32, 64, 64], 'n_layers': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 131 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 129    | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "131 K     Trainable params\n",
      "0         Non-trainable params\n",
      "131 K     Total params\n",
      "0.525     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab81524de354306b1b06df7243afb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c3162391ca4afab8a0a292d519dac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea36dd608a44a6d9b166c74b2bac257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be59b03ff3d04488911c844f79f74260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 182.99 seconds\n",
      "{'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 2, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.001\\n    lr: 0.001\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.001, 'validation_loss': 0.3222886025905609, 'training_time': 182.98674154281616, 'retraining': False}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00\\GRUseq2seq_[32, 64, 64]hid_3l_lr0.001_drop[0.3, 0.3, 0.3].ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00\\model_weights.pth\n",
      "Training completed successfully.\n",
      "Model 1 completed. Validation Loss: 0.3223. Checkpoints saved to: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-19-00\n",
      "\n",
      "Training model 2/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [32, 64, 64], 'n_layers': 3, 'dropout': 0, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 131 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 129    | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "131 K     Trainable params\n",
      "0         Non-trainable params\n",
      "131 K     Total params\n",
      "0.525     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cb8f22e13742c1b1aa2744d42440c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6c67c869664c60bc2c8052d26ebdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ee88e64ddb4833b9812c40dcc837a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08cd1a7cae946b697f0df204b117a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 174 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 129    | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "174 K     Trainable params\n",
      "0         Non-trainable params\n",
      "174 K     Total params\n",
      "0.699     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 159.52 seconds\n",
      "{'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 2, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.001\\n    lr: 0.001\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.001, 'validation_loss': 0.22031576931476593, 'training_time': 159.52273654937744, 'retraining': False}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03\\GRUseq2seq_[32, 64, 64]hid_3l_lr0.001_drop[0, 0, 0].ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03\\model_weights.pth\n",
      "Training completed successfully.\n",
      "Model 2 completed. Validation Loss: 0.2203. Checkpoints saved to: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[32, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-22-03\n",
      "\n",
      "Training model 3/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [32, 64, 64], 'n_layers': 2, 'dropout': 0.3, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "Error in model 3: The length of hid_dim (3) must match n_layers (2).\n",
      "\n",
      "Training model 4/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [32, 64, 64], 'n_layers': 2, 'dropout': 0, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "Error in model 4: The length of hid_dim (3) must match n_layers (2).\n",
      "\n",
      "Training model 5/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [64, 64, 64], 'n_layers': 3, 'dropout': 0.3, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43\n",
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c91dba6e44dc5be27b3eeb4d219df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6f687227e543269cab502104e64fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1513286fd1ee47c6b311690e9bc1041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a186ad68884537b026edbd879697d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Catia Bastos\\dev\\envs\\NeuralLibraryEnv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-27-54 exists and is not empty.\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | gru_layers     | ModuleList        | 174 K  | train\n",
      "1 | dropout_layers | ModuleList        | 0      | train\n",
      "2 | fc_out         | Linear            | 129    | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "-------------------------------------------------------------\n",
      "174 K     Trainable params\n",
      "0         Non-trainable params\n",
      "174 K     Total params\n",
      "0.699     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 190.63 seconds\n",
      "{'architecture': 'GRUseq2seq', 'model_name': 'ECGPeakDetector', 'train_dataset': 'private_gib01', 'task': 'peak detection', 'gpu_model': None, 'epochs': 2, 'optimizer': 'Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.001\\n    lr: 0.001\\n    maximize: False\\n    weight_decay: 1e-05\\n)', 'learning_rate': 0.001, 'validation_loss': 0.30796414613723755, 'training_time': 190.6270203590393, 'retraining': False}\n",
      "Training complete. Best_model_path: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43\\GRUseq2seq_[64, 64, 64]hid_3l_lr0.001_drop[0.3, 0.3, 0.3].ckpt\n",
      "Weights saved as C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43\\model_weights.pth\n",
      "Training completed successfully.\n",
      "Model 5 completed. Validation Loss: 0.3080. Checkpoints saved to: C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0.3, 0.3, 0.3]_dt2025-01-31_11-24-43\n",
      "\n",
      "Training model 6/16 with parameters: {'model_name': 'ECGPeakDetector', 'n_features': 1, 'hid_dim': [64, 64, 64], 'n_layers': 3, 'dropout': 0, 'learning_rate': 0.001, 'bidirectional': True, 'task': 'classification', 'num_classes': 1}\n",
      "No GPU available, using CPU.\n",
      "Checkpoints directory created at C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-27-54\n",
      "TensorBoard logs will be saved to C:\\Users\\Catia Bastos\\dev\\results\\ECGPeakDetector\\checkpoints\\GRUseq2seq_[64, 64, 64]hid_3l_bidirTrue_lr0.001_drop[0, 0, 0]_dt2025-01-31_11-27-54\\tensorboard_logs\\version_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b72294136948f2b2b13a900b8ad400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc2b58bc11b40b7a06653899dfa782b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be7093a1ad1469daa507d4e6aa713c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24482ef09c9c4406861ef5ebd20dc104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dir, best_val_loss, val_losses = arc.run_grid_search(architecture_name, archi_params_options, train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542d8be-3a35-4073-a9ce-ecc4eed0631f",
   "metadata": {},
   "source": [
    "### Step 3: Test the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76730a9-6878-4af6-a052-e967c4b5b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Load architecture parameters from the hparams.yaml file\n",
    "architecture_params = arc.get_hparams_from_checkpoints(best_dir)\n",
    "# 3.2 Initialize the model using the loaded parameters\n",
    "model = arc.GRUseq2seq(**architecture_params)\n",
    "\n",
    "predictions, avg_loss = model.test_on_test_set(\n",
    "    path_x=train_params[\"path_x\"],\n",
    "    path_y=train_params[\"path_y\"],\n",
    "    checkpoints_dir=best_dir,\n",
    "    gpu_id=train_params[\"gpu_id\"],\n",
    "    save_predictions=True,\n",
    "    all_samples=False,\n",
    "    samples=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59427496-d909-4f2e-8f05-519aca33015a",
   "metadata": {},
   "source": [
    "### Step 4: Test the best model on a single signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59d888-e222-4a60-910b-d57457990ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_signal = torch.rand(100, 1)  # Example input signal (sequence length: 100, 1 feature)\n",
    "single_prediction = model.test_on_single_signal(single_signal, checkpoints_dir=best_dir, gpu_id=train_params[\"gpu_id\"])\n",
    "print(f\"Single Signal Prediction: {single_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NeuralLibraryEnv)",
   "language": "python",
   "name": "neurallibraryenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
